#singleton(Class with a Single Instance)

object HelloWorld {
  def main(args: Array[String]) {
    println("Hello, world!")
  }
}

#compiling:
scalac HelloWorld.scala
HelloWorld.main(Array())

#importing classes & packages
import java.util.{Date, Locale}
import java.text.DateFormat
import java.text.DateFormat._

#functions are also objects in Scala. 

#Case Classes
case classes are used to conveniently store and match on the contents of a class. You can construct them without using new.

# Word Count in Scala-Spark

val textFile = sc.textFile("hdfs://...")
val counts = textFile.flatMap(line => line.split(" "))
                 .map(word => (word, 1))
                 .reduceByKey(_ + _)
counts.saveAsTextFile("hdfs://...")            

#Converting a given file in One format to one diff format

import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext._
object fileconv {
def main(args: Array[String]) {
val conf = new SparkConf().setAppName("Text all")   ---Name of the object should match name of the file
val sc = new SparkContext(conf)
Val textFilRDD = sc.textFile("hdfs://.....")
textFilRDD.saveAsSequenceFile("hdfs dest path")
textFilRDD.saveAsObjectFile("hdfs path")
}
}

#Reading a Sequence File
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext._
object Sequencefle {
def main(args: Array[String]) {
val conf = new Sparkconf().setAppName("SeqFile").setMaster("local[2]")
val sc = nee SparkContext(conf)
val seqfile = sc.sequenceFile("hdfs path",classOf[Text], classOf[Text]))
                . map{case (x, y) => (x.toString, y.get())}
               # . map(x => x.toString().collect().foreach(println)
}
}

#reading sequence file
object Seeqfile {
def main (args: Array[String]) {
val conf = new SparkConf().setAppName("Sequence")
val sc = new SparkContext(conf)
val seqfile = sc.sequenceFile("/user/cloudera/spark/departmentsSeq", classOf[IntWritable], classOf[Text])
             .map(rec => rec.toString()).collect().foreach(println)
}
}




